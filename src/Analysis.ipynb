{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26541f7",
   "metadata": {},
   "source": [
    "# This notebook serves as the executable software that reads in datasets, combines datasets, and runs data analysis\n",
    "\n",
    "The end goal is to perform analysis on how the coverage of US cities on wikipedia and how the quality of articles about cities varies among states. \n",
    "\n",
    "Steps: \n",
    "1. Confirm datasets are ready to go.\n",
    "1. Combine dataset of wikipedia articles with a dataset of state populations\n",
    "2. Use ORES to estiamte quality of articles about the cities\n",
    "3. Data analyis\n",
    "   3a. The states with the greatest and least coverage of cities on Wikipedia compared  \n",
    "       to their population.\n",
    "   3b. The states with the highest and lowest proportion of high quality articles about cities.\n",
    "   3c. A ranking of US geographic regions by articles-per-person and proportion of high \n",
    "       quality articles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dda906",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca01406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import base64\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1671f61",
   "metadata": {},
   "source": [
    "# Part 1. Confirm datasets are ready to go. \n",
    "\n",
    "Confirm that the files below are there:  \n",
    "./data/PopulationEstimates.csv   \n",
    "./data/States_by_region.csv  \n",
    "./data/us_cities_by_state_SEPT2023.csv  \n",
    "\n",
    "#### Step 1A: Read in ./data/PopulationEstimates.csv as csv object.\n",
    "    ##### Step 1A1: Store only state and population data from csv into list for just states. \n",
    "    ####  Step 1A2: Output first, middle, and last row of csv object to confirm data is in memory. \n",
    "#### Step 1B: Read in ./data/States_by_region.csv as csv object.\n",
    "    ##### Step 1B1: Store all data from csv into list. \n",
    "    ##### Step 1B2: Remove header row from list to prevent it showing up later.    \n",
    "    ##### Step 1B3: Output first, middle, and last row of csv object to confirm data is in memory. \n",
    "#### Step 1C: Read in ./data/us_cities_by_state_SEPT2023.csv as csv object.\n",
    "    ##### Step 1C1: Store all data from csv into list. \n",
    "    ##### Step 1C2: Remove header row from list to prevent it showing up later.    \n",
    "    ##### Step 1C3: Output first, middle, and last row of csv object to confirm data is in memory. \n",
    "\n",
    "### Data sources: \n",
    "##### ./data/PopulationEstimates.csv  \n",
    "https://www2.census.gov/programs-surveys/popest/datasets/2020-2022/state/totals/NST-EST2022-ALLDATA.csv    \n",
    "https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html  \n",
    "##### ./data/States_by_region.csv    \n",
    "The shared google drive for Homework 2 by UW Data 512 provides this file.   \n",
    "##### ./data/us_cities_by_state_SEPT2023.csv  \n",
    "The shared google drive for Homework 2 by UW data 512 provies this file.   \n",
    "However the Wikipedia Category:Lists of cities in the United States by   \n",
    "state was crawled to generate a list of Wikipedia article pages about US  \n",
    "cities from each state.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6140bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states, should be 50: 50\n",
      "['Alabama', '5074296']\n",
      "['Montana', '1122867']\n",
      "['Wyoming', '581381']\n"
     ]
    }
   ],
   "source": [
    "# Step 1A: Read in ./data/PopulationEstimates.csv as csv object.\n",
    "StatePopEstimates = []\n",
    "RegionalPopEstimates = []\n",
    "with open('../data/PopulationEstimates.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # Step 1A1: Store only state and population data from csv into list for just states. \n",
    "    #  This means excluding the first 15 and the last rows, which correspond to \n",
    "    #  the header row, larger regions of the United States, and Puerto Rico, which are not states. \n",
    "    counter = 0\n",
    "    for row in reader: \n",
    "        if(counter > 14 and counter < 66):\n",
    "            StatePopEstimates.append([row[4], row[8]])\n",
    "        elif(counter < 15):\n",
    "            RegionalPopEstimates.append([row[4], row[8]])\n",
    "        counter += 1\n",
    "        \n",
    "#Remove header, and US population\n",
    "RegionalPopEstimates.pop(0)\n",
    "RegionalPopEstimates.pop(0)\n",
    "\n",
    "# 1A1: Remove district of columbia\n",
    "StatePopEstimates.pop(8)\n",
    "        \n",
    "# Step 1A2: Output first, middle, and last row of csv object to confirm data is in memory.  \n",
    "print(\"Number of states, should be 50:\", len(StatePopEstimates))\n",
    "print(StatePopEstimates[0])\n",
    "print(StatePopEstimates[len(StatePopEstimates)//2])\n",
    "print(StatePopEstimates[len(StatePopEstimates)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a62a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states, should be 50: 50\n",
      "['Northeast', 'New England', 'Connecticut']\n",
      "['South', 'South Atlantic', 'North Carolina']\n",
      "['West', 'Pacific', 'Washington']\n"
     ]
    }
   ],
   "source": [
    "# Step 1B: Read in ./data/States_by_region.csv as csv object.\n",
    "StateRegions = []\n",
    "with open('../data/States_by_region.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # Step 1B1: Store all data from csv into list. \n",
    "    for row in reader: \n",
    "        StateRegions.append([row[0], row[1], row[2]]) \n",
    "\n",
    "# Step 1B2: Remove header row\n",
    "StateRegions.pop(0)\n",
    "\n",
    "# Step 1B3: Output first, middle, and last row of csv object to confirm data is in memory.\n",
    "print(\"Number of states, should be 50:\", len(StateRegions))\n",
    "print(StateRegions[0])\n",
    "print(StateRegions[len(StateRegions)//2])\n",
    "print(StateRegions[len(StateRegions)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b33f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama', 'Abbeville, Alabama', 'https://en.wikipedia.org/wiki/Abbeville,_Alabama']\n",
      "['Minnesota', 'Sargeant, Minnesota', 'https://en.wikipedia.org/wiki/Sargeant,_Minnesota']\n",
      "['Wyoming', 'Yoder, Wyoming', 'https://en.wikipedia.org/wiki/Yoder,_Wyoming']\n"
     ]
    }
   ],
   "source": [
    "#### Step 1C: Read in ./data/us_cities_by_state_SEPT2023.csv as csv object.\n",
    "CityArticles = []\n",
    "with open('../data/us_cities_by_state_SEPT2023.csv', newline='', encoding=\"utf8\") as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # Step 1C1: Store all data from csv into list. \n",
    "    for row in reader: \n",
    "        CityArticles.append([row[0], row[1], row[2]]) \n",
    "\n",
    "# Step 1C2: Remove header row\n",
    "CityArticles.pop(0)\n",
    "\n",
    "# Step 1C3: Output first, middle, and last row of csv object to confirm data is in memory.\n",
    "print(CityArticles[0])\n",
    "print(CityArticles[len(CityArticles)//2])\n",
    "print(CityArticles[len(CityArticles)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948128c0",
   "metadata": {},
   "source": [
    "# Part 2. Get Article Quality Predictions\n",
    "We're using a machine learning system called ORES. This was originally an acronym for \"Objective Revision Evaluation Service\" but was simply renamed “ORES”. ORES is a machine learning tool that can provide estimates of Wikipedia article quality. The article quality estimates are, from best to worst:\n",
    "FA - Featured article\n",
    "GA - Good article (sometimes called A-class)\n",
    "B - B-class article\n",
    "C - C-class article\n",
    "Start - Start-class article\n",
    "Stub - Stub-class article\n",
    "These labelings were learned based on articles in Wikipedia that were peer-reviewed using the Wikipedia content assessment procedures.These quality classes are a subset of quality assessment categories developed by Wikipedia editors.\n",
    "\n",
    "#### Step 2A: Create wikimedia user account to generate API token. \n",
    "    ##### Step 2A1: Create account here: https://api.wikimedia.org/w/index.php?title=Special:UserLogin \n",
    "    ##### Step 2A2: Then go here to create token: https://api.wikimedia.org/wiki/Special:AppManagement\n",
    "    ##### Step 2A3: Click Create key, choosen personal API token, checkmark all permsissions\n",
    "#### Step 2B: Define constants/functions to make data requests.\n",
    "    ##### Step 2B1: Create function to load in credentials from text file which is not allowed to be pushed to the repo.\n",
    "    ##### Step 2B2: Define functions and constants for pageinfo API. \n",
    "    ##### Step 2B3: Define functions and constants for ORES API. \n",
    "#### Step 2C: Load in credentials\n",
    "#### Step 2D: Get ORES score for each city article. \n",
    "    ##### Step 2D1: Read each line of us_cities_by_state_SEPT.2023.csv\n",
    "    ##### Step 2D2: Make a page info request to get the current article page revision\n",
    "    ##### Step 2D3: Make an ORES request using the page title and current revision id.\n",
    "    ##### Step 2D4: Store score predictions if possible, else print out failures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136a3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded successfully:\n"
     ]
    }
   ],
   "source": [
    "# Step 2B1: Create function to load in credentials from text file which is not allowed to be pushed to the repository.\n",
    "def load_credentials_from_file(filename):\n",
    "    '''\n",
    "    Description:\n",
    "        Given a text file with six lines, where the second, fourth, and sixth lines are\n",
    "        respectively client id, client secret acess token, and acess token, reads the text file\n",
    "        and loads those lines into memory as variables. \n",
    "    Inputs:\n",
    "        filename - String - Path of file\n",
    "    Outputs:\n",
    "        client_id - String\n",
    "        client_secret - String\n",
    "        access_token - String\n",
    "    Notes:\n",
    "        This function below was generated by chatGPT. https://chat.openai.com/ \n",
    "        Prompt used:\n",
    "            \"Given a text file with 6 lines, where the 2nd, 4th, and 6th lines \n",
    "             are a client id, client secret access token, and access token,\n",
    "             give me a python function that that reads in a text file and loads \n",
    "             those lines into memory as variables. Make sure to close the file.\"\n",
    "        Why: \n",
    "            Wanted to save time, knew how to explain the problem, simple code to generate.\n",
    "    '''\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        if len(lines) >= 6:\n",
    "            client_id = lines[1].strip()\n",
    "            client_secret = lines[3].strip()\n",
    "            access_token = lines[5].strip()\n",
    "            return client_id, client_secret, access_token\n",
    "        else:\n",
    "            print(\"Error: The file does not contain enough lines.\")\n",
    "            return None, None, None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An unexpected error occurred - {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9905468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2B2: Define functions and constants for pageinfo API. \n",
    "\n",
    "# The code in this cell was developed by Dr. David W. McDonald for use in DATA 512, \n",
    "# a course in the UW MS Data Science degree program. \n",
    "# This code is provided under the Creative Commons CC-BY license. Revision 1.1 - August 14, 2022\n",
    "# Any modifications made to the original source also fall under the CC-BY license. \n",
    "\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. \n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (60.0/5000.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<uwnetid@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for what can be included.\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = { \"action\": \"query\", \"format\": \"json\", \"titles\": \"\", \"prop\": \"info\",\n",
    "                            \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    '''\n",
    "    Description:\n",
    "        Make request to endpoint with supplied arguments.\n",
    "    Inputs:\n",
    "        article_title - String\n",
    "        endpoint_url - String\n",
    "        request_template - Dictionary\n",
    "        headers - Dictionary\n",
    "    Output:\n",
    "        Dictionary\n",
    "    '''\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4383629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2B3: Define functions and constants for ORES API. \n",
    "\n",
    "# The code in this cell was developed by Dr. David W. McDonald for use in DATA 512, \n",
    "# a course in the UW MS Data Science degree program. \n",
    "# This code is provided under the Creative Commons CC-BY license. Revision 1.1 - August 15, 2023\n",
    "# Any modifications made to the original source also fall under the CC-BY license. \n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<zbowyer@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer )\" + str(access_token)\n",
    "}\n",
    "\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"zbowyer@uw.edu\",         # your email address should go here\n",
    "    'access_token'  : access_token          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    '''\n",
    "    Description:\n",
    "        Attempts to get ORES score from API call with supplied arguments.\n",
    "    Inputs:\n",
    "        article_revid - Integer\n",
    "        email_address - String\n",
    "        access_token - String\n",
    "        endpoint_url - String\n",
    "        model_name - String\n",
    "        request_data - Dictionary\n",
    "        header_format - Dictionary\n",
    "        header_params - Dictionary\n",
    "    Output:\n",
    "        Dictionary\n",
    "    '''\n",
    "    \n",
    "    # Make sure we have an article revision id, email and token\n",
    "    # This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid: request_data['rev_id'] = article_revid\n",
    "    if email_address: header_params['email_address'] = email_address\n",
    "    if access_token: header_params['access_token'] = access_token\n",
    "    \n",
    "    # Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']: raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']: raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']: raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        #print(request_url, headers, request_data)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(\"Exception\", e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b9be8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded successfully:\n"
     ]
    }
   ],
   "source": [
    "# Step 2C: Load in credentials\n",
    "filename = '../auth.txt'\n",
    "client_id, client_secret, access_token = load_credentials_from_file(filename)\n",
    "\n",
    "if client_id is not None and client_secret is not None and access_token is not None:\n",
    "    print(\"Credentials loaded successfully:\")\n",
    "else:\n",
    "    print(\"Failed to load credentials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb996cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████▉                                                               | 7599/22157 [1:40:00<3:38:21,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Expecting value: line 1 column 1 (char 0)\n",
      "Could not find result for Chester, Maine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████▏                                                         | 8815/22157 [1:56:07<3:07:14,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Expecting value: line 1 column 1 (char 0)\n",
      "Could not find result for Champion Township, Michigan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 22157/22157 [4:52:54<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 2D: Get ORES score for each city article. \n",
    "# Step 2D1: Read each line of us_cities_by_state_SEPT.2023.csv\n",
    "for i in tqdm(range(len(CityArticles))):\n",
    "    article_title = CityArticles[i][1]\n",
    "    article_url = CityArticles[i][2]\n",
    "    \n",
    "    # Step 2D2: Make a page info request to get the current article page revision\n",
    "    PageData = request_pageinfo_per_article(article_title)\n",
    "    pageid = list(PageData[\"query\"][\"pages\"].keys())[0]\n",
    "    revid = int(PageData[\"query\"][\"pages\"][pageid][\"lastrevid\"])\n",
    "    article_dict = {article_title: revid}\n",
    "    \n",
    "    # Step 2D3: Make an ORES request using the page title and current revision id.\n",
    "    score = request_ores_score_per_article(article_revid=revid, email_address=\"zbowyer@uw.edu\", access_token=access_token)\n",
    "    \n",
    "    # Step 2D4: Store score predictions if possible, else print out failures. \n",
    "    try:\n",
    "        ORES_prediction = score[\"enwiki\"][\"scores\"][str(revid)][\"articlequality\"][\"score\"][\"prediction\"]\n",
    "        CityArticles[i].append(ORES_prediction)\n",
    "        #CityArticles[i].append(revid)\n",
    "    except:\n",
    "        print(\"Could not find result for\", article_title)\n",
    "        CityArticles[i].append(\"N/A\")\n",
    "        #CityArticles[i].append(revid)\n",
    "        #print(article_title, \":\", ORES_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e287eb",
   "metadata": {},
   "source": [
    "# Step 3: Combine datasets\n",
    "\n",
    "The goal here is to merge the wikipedia data and population data together.   \n",
    "This can be done because both datasets have state name fields.  \n",
    "Additionally regional-devisions must be added, so a third dataset will be combined.  \n",
    "\n",
    "All data with no matches should be logged.  \n",
    "\n",
    "#### Step 3A: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "788c6773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state        article_title  \\\n",
      "0  Alabama   Abbeville, Alabama   \n",
      "1  Alabama  Adamsville, Alabama   \n",
      "2  Alabama     Addison, Alabama   \n",
      "3  Alabama       Akron, Alabama   \n",
      "4  Alabama   Alabaster, Alabama   \n",
      "\n",
      "                                                 url article_quality  \\\n",
      "0   https://en.wikipedia.org/wiki/Abbeville,_Alabama               C   \n",
      "1  https://en.wikipedia.org/wiki/Adamsville,_Alabama               C   \n",
      "2     https://en.wikipedia.org/wiki/Addison,_Alabama               C   \n",
      "3       https://en.wikipedia.org/wiki/Akron,_Alabama              GA   \n",
      "4   https://en.wikipedia.org/wiki/Alabaster,_Alabama               C   \n",
      "\n",
      "  state_population region   regional_division region_population  \n",
      "0          5074296  South  East South Central          19578002  \n",
      "1          5074296  South  East South Central          19578002  \n",
      "2          5074296  South  East South Central          19578002  \n",
      "3          5074296  South  East South Central          19578002  \n",
      "4          5074296  South  East South Central          19578002  \n"
     ]
    }
   ],
   "source": [
    "#Get data into dataframes, save cityarticles because it took a long time to generate\n",
    "CityArticles_dataframe = pd.DataFrame(CityArticles, columns = ['state', 'article_title', 'url', 'article_quality'])\n",
    "CityArticles_dataframe.to_csv(\"../data/CityArticles_withscores.csv\")\n",
    "StateRegions_dataframe = pd.DataFrame(StateRegions, columns = ['region', 'regional_division', 'state'])\n",
    "StatePopEstimates_dataframe = pd.DataFrame(StatePopEstimates, columns = ['state', 'state_population'])\n",
    "RegionalPopEstimates_dataframe = pd.DataFrame(RegionalPopEstimates, columns = ['regional_division', 'region_population'])\n",
    "\n",
    "df3 = CityArticles_dataframe.merge(StatePopEstimates_dataframe, how='inner',left_on='state', right_on='state')\n",
    "df4 = df3.merge(StateRegions_dataframe, how='inner',left_on='state', right_on='state')\n",
    "df5 = df4.merge(RegionalPopEstimates_dataframe, how='inner', left_on='regional_division', right_on='regional_division')\n",
    "df5.to_csv(\"../data/wp_scored_city_articles_by_state.csv\")\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafa828",
   "metadata": {},
   "source": [
    "# Step 4: Analysis\n",
    "\n",
    "The goal here is to calculate metrics for our dataset. \n",
    "\n",
    "### For each state, and each division:\n",
    "    Total-articles-per-population (number of articles per person)  \n",
    "    High quality articles per population (number of high quality articles per person) (FA OR GA)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "75290f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    regional_division  article_number  region_population  \\\n",
      "0  East North Central             710           47097779   \n",
      "1  East South Central             369           19578002   \n",
      "2     Middle Atlantic             566           41910858   \n",
      "3            Mountain             311           25514320   \n",
      "4         New England             149           15129548   \n",
      "5             Pacific             490           53229044   \n",
      "6      South Atlantic             222           67452940   \n",
      "7  West North Central             558           21689816   \n",
      "8  West South Central             640           41685250   \n",
      "\n",
      "   quality_article_number_per_capita  \n",
      "0                           0.000015  \n",
      "1                           0.000019  \n",
      "2                           0.000014  \n",
      "3                           0.000012  \n",
      "4                           0.000010  \n",
      "5                           0.000009  \n",
      "6                           0.000003  \n",
      "7                           0.000026  \n",
      "8                           0.000015  \n"
     ]
    }
   ],
   "source": [
    "#Total articles per capita (STATE)\n",
    "States_num_articles = pd.DataFrame(df5.groupby('state').count()[\"article_title\"])\n",
    "States_num_articles = States_num_articles.rename(columns={\"article_title\": \"article_number\"})\n",
    "States_num_articles = States_num_articles.merge(StatePopEstimates_dataframe, how='inner',left_on='state', right_on='state')\n",
    "States_num_articles = States_num_articles.astype({'state_population': 'int32'})\n",
    "States_num_articles[\"article_number_per_capita\"] = States_num_articles[\"article_number\"] / States_num_articles[\"state_population\"]\n",
    "#print(States_num_articles)\n",
    "\n",
    "#Total articles per capita (Division)\n",
    "Divisions_num_articles = pd.DataFrame(df5.groupby('regional_division').count()[\"article_title\"])\n",
    "Divisions_num_articles = Divisions_num_articles.rename(columns={\"article_title\": \"article_number\"})\n",
    "Divisions_num_articles = Divisions_num_articles.merge(RegionalPopEstimates_dataframe, how='inner',left_on='regional_division', right_on='regional_division')\n",
    "Divisions_num_articles = Divisions_num_articles.astype({'region_population': 'int32'})\n",
    "Divisions_num_articles[\"article_number_per_capita\"] = Divisions_num_articles[\"article_number\"] / Divisions_num_articles[\"region_population\"]\n",
    "#print(Divisions_num_articles)\n",
    "\n",
    "#Filter on only FA or GAs\n",
    "GA_or_FA = df5[df5['article_quality'].isin(['FA', 'GA'])]\n",
    "\n",
    "#Total high quality articles per capita (STATE)\n",
    "State_numquality_articles = GA_or_FA.groupby('state')['article_quality'].count().reset_index()\n",
    "State_numquality_articles = State_numquality_articles.merge(StatePopEstimates_dataframe, how='inner',left_on='state', right_on='state')\n",
    "State_numquality_articles = State_numquality_articles.rename(columns={\"article_quality\": \"article_number\"})\n",
    "State_numquality_articles = State_numquality_articles.astype({'state_population': 'int32'})\n",
    "State_numquality_articles[\"quality_article_number_per_capita\"] = State_numquality_articles[\"article_number\"] / State_numquality_articles[\"state_population\"]\n",
    "#print(State_numquality_articles)\n",
    "\n",
    "#Total high quality articles per capita (Division)\n",
    "Divisions_numquality_articles = GA_or_FA.groupby('regional_division')['article_quality'].count().reset_index()\n",
    "Divisions_numquality_articles = Divisions_numquality_articles.merge(RegionalPopEstimates_dataframe, how='inner',left_on='regional_division', right_on='regional_division')\n",
    "Divisions_numquality_articles = Divisions_numquality_articles.rename(columns={\"article_quality\": \"article_number\"})\n",
    "Divisions_numquality_articles = Divisions_numquality_articles.astype({'region_population': 'int32'})\n",
    "Divisions_numquality_articles[\"quality_article_number_per_capita\"] = Divisions_numquality_articles[\"article_number\"] / Divisions_numquality_articles[\"region_population\"]\n",
    "print(Divisions_numquality_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7459bfd",
   "metadata": {},
   "source": [
    "# Step 5: Results\n",
    "\n",
    "#### The goal here is to produce six tables that show:\n",
    "1. Top 10 US states by coverage: The 10 US states with the highest total articles per capita (in descending order).  \n",
    "2. Bottom 10 US states by coverage: The 10 US states with the lowest total articles per capita (in ascending order).  \n",
    "3. Top 10 US states by high quality: The 10 US states with the highest high quality articles per capita (in descending order).  \n",
    "4. Bottom 10 US states by high quality: The 10 US states with the lowest high quality articles per capita (in ascending order).  \n",
    "5. Census divisions by total coverage: A rank ordered list of US census divisions (in descending order) by total articles per capita.  \n",
    "6. Census divisions by high quality coverage: Rank ordered list of US census divisions (in descending order) by high quality articles per capita.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1ca2659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>article_number</th>\n",
       "      <th>state_population</th>\n",
       "      <th>article_number_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>329</td>\n",
       "      <td>647064</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Maine</td>\n",
       "      <td>483</td>\n",
       "      <td>1385340</td>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>1043</td>\n",
       "      <td>3200517</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>149</td>\n",
       "      <td>733583</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2556</td>\n",
       "      <td>12972008</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>922</td>\n",
       "      <td>5074296</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>1773</td>\n",
       "      <td>10034113</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>99</td>\n",
       "      <td>581381</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>500</td>\n",
       "      <td>3045637</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>951</td>\n",
       "      <td>6177957</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  article_number  state_population  article_number_per_capita\n",
       "32       Vermont             329            647064                   0.000508\n",
       "16         Maine             483           1385340                   0.000349\n",
       "12          Iowa            1043           3200517                   0.000326\n",
       "1         Alaska             149            733583                   0.000203\n",
       "28  Pennsylvania            2556          12972008                   0.000197\n",
       "0        Alabama             922           5074296                   0.000182\n",
       "19      Michigan            1773          10034113                   0.000177\n",
       "36       Wyoming              99            581381                   0.000170\n",
       "3       Arkansas             500           3045637                   0.000164\n",
       "22      Missouri             951           6177957                   0.000154"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Top 10 US states by coverage: The 10 US states with the highest total articles per capita (in descending order).  \n",
    "States_num_articles.sort_values(by='article_number_per_capita', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a805149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>article_number</th>\n",
       "      <th>state_population</th>\n",
       "      <th>article_number_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>19</td>\n",
       "      <td>3177772</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>482</td>\n",
       "      <td>39029342</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>91</td>\n",
       "      <td>7359197</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>413</td>\n",
       "      <td>22244823</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>75</td>\n",
       "      <td>4019800</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>63</td>\n",
       "      <td>2937150</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>157</td>\n",
       "      <td>6164660</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>266</td>\n",
       "      <td>8683619</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>193</td>\n",
       "      <td>5892539</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Washington</td>\n",
       "      <td>281</td>\n",
       "      <td>7785786</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         state  article_number  state_population  article_number_per_capita\n",
       "24      Nevada              19           3177772                   0.000006\n",
       "4   California             482          39029342                   0.000012\n",
       "2      Arizona              91           7359197                   0.000012\n",
       "7      Florida             413          22244823                   0.000019\n",
       "26    Oklahoma              75           4019800                   0.000019\n",
       "13      Kansas              63           2937150                   0.000021\n",
       "17    Maryland             157           6164660                   0.000025\n",
       "33    Virginia             266           8683619                   0.000031\n",
       "35   Wisconsin             193           5892539                   0.000033\n",
       "34  Washington             281           7785786                   0.000036"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Bottom 10 US states by coverage: The 10 US states with the lowest total articles per capita (in ascending order).  \n",
    "States_num_articles.sort_values(by='article_number_per_capita', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fe92554f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>article_number</th>\n",
       "      <th>state_population</th>\n",
       "      <th>quality_article_number_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>45</td>\n",
       "      <td>647064</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>39</td>\n",
       "      <td>581381</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Montana</td>\n",
       "      <td>55</td>\n",
       "      <td>1122867</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>566</td>\n",
       "      <td>12972008</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>263</td>\n",
       "      <td>6177957</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>31</td>\n",
       "      <td>733583</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>141</td>\n",
       "      <td>4240137</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>105</td>\n",
       "      <td>3200517</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Maine</td>\n",
       "      <td>43</td>\n",
       "      <td>1385340</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>168</td>\n",
       "      <td>5717184</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  article_number  state_population  \\\n",
       "32       Vermont              45            647064   \n",
       "36       Wyoming              39            581381   \n",
       "23       Montana              55           1122867   \n",
       "28  Pennsylvania             566          12972008   \n",
       "22      Missouri             263           6177957   \n",
       "1         Alaska              31            733583   \n",
       "27        Oregon             141           4240137   \n",
       "12          Iowa             105           3200517   \n",
       "16         Maine              43           1385340   \n",
       "20     Minnesota             168           5717184   \n",
       "\n",
       "    quality_article_number_per_capita  \n",
       "32                           0.000070  \n",
       "36                           0.000067  \n",
       "23                           0.000049  \n",
       "28                           0.000044  \n",
       "22                           0.000043  \n",
       "1                            0.000042  \n",
       "27                           0.000033  \n",
       "12                           0.000033  \n",
       "16                           0.000031  \n",
       "20                           0.000029  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Top 10 US states by high quality: The 10 US states with the highest number of high quality articles per capita (in descending order).\n",
    "State_numquality_articles.sort_values(by='quality_article_number_per_capita', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "66f8f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>article_number</th>\n",
       "      <th>state_population</th>\n",
       "      <th>quality_article_number_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>8</td>\n",
       "      <td>3177772</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>24</td>\n",
       "      <td>7359197</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>36</td>\n",
       "      <td>8683619</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>173</td>\n",
       "      <td>39029342</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>119</td>\n",
       "      <td>22244823</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>42</td>\n",
       "      <td>6164660</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>22</td>\n",
       "      <td>2937150</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>33</td>\n",
       "      <td>4019800</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>61</td>\n",
       "      <td>6981974</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>44</td>\n",
       "      <td>4590241</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  article_number  state_population  \\\n",
       "24         Nevada               8           3177772   \n",
       "2         Arizona              24           7359197   \n",
       "33       Virginia              36           8683619   \n",
       "4      California             173          39029342   \n",
       "7         Florida             119          22244823   \n",
       "17       Maryland              42           6164660   \n",
       "13         Kansas              22           2937150   \n",
       "26       Oklahoma              33           4019800   \n",
       "18  Massachusetts              61           6981974   \n",
       "15      Louisiana              44           4590241   \n",
       "\n",
       "    quality_article_number_per_capita  \n",
       "24                           0.000003  \n",
       "2                            0.000003  \n",
       "33                           0.000004  \n",
       "4                            0.000004  \n",
       "7                            0.000005  \n",
       "17                           0.000007  \n",
       "13                           0.000007  \n",
       "26                           0.000008  \n",
       "18                           0.000009  \n",
       "15                           0.000010  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Bottom 10 US states by high quality: The 10 US states with the lowest high quality articles per capita (in ascending order).\n",
    "State_numquality_articles.sort_values(by='quality_article_number_per_capita', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0097ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>article_number</th>\n",
       "      <th>region_population</th>\n",
       "      <th>article_number_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>2911</td>\n",
       "      <td>21689816</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>1992</td>\n",
       "      <td>19578002</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>4755</td>\n",
       "      <td>47097779</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New England</td>\n",
       "      <td>1164</td>\n",
       "      <td>15129548</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Middle Atlantic</td>\n",
       "      <td>2556</td>\n",
       "      <td>41910858</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>2106</td>\n",
       "      <td>41685250</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>1105</td>\n",
       "      <td>25514320</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>1304</td>\n",
       "      <td>53229044</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>893</td>\n",
       "      <td>67452940</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regional_division  article_number  region_population  \\\n",
       "7  West North Central            2911           21689816   \n",
       "1  East South Central            1992           19578002   \n",
       "0  East North Central            4755           47097779   \n",
       "4         New England            1164           15129548   \n",
       "2     Middle Atlantic            2556           41910858   \n",
       "8  West South Central            2106           41685250   \n",
       "3            Mountain            1105           25514320   \n",
       "5             Pacific            1304           53229044   \n",
       "6      South Atlantic             893           67452940   \n",
       "\n",
       "   article_number_per_capita  \n",
       "7                   0.000134  \n",
       "1                   0.000102  \n",
       "0                   0.000101  \n",
       "4                   0.000077  \n",
       "2                   0.000061  \n",
       "8                   0.000051  \n",
       "3                   0.000043  \n",
       "5                   0.000024  \n",
       "6                   0.000013  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Census divisions by total coverage: A rank ordered list of US census divisions (in descending order) by total articles per capita.\n",
    "Divisions_num_articles.sort_values(by='article_number_per_capita', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c6168944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>article_number</th>\n",
       "      <th>region_population</th>\n",
       "      <th>quality_article_number_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>558</td>\n",
       "      <td>21689816</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>369</td>\n",
       "      <td>19578002</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>640</td>\n",
       "      <td>41685250</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>710</td>\n",
       "      <td>47097779</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Middle Atlantic</td>\n",
       "      <td>566</td>\n",
       "      <td>41910858</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>311</td>\n",
       "      <td>25514320</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New England</td>\n",
       "      <td>149</td>\n",
       "      <td>15129548</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>490</td>\n",
       "      <td>53229044</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>222</td>\n",
       "      <td>67452940</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regional_division  article_number  region_population  \\\n",
       "7  West North Central             558           21689816   \n",
       "1  East South Central             369           19578002   \n",
       "8  West South Central             640           41685250   \n",
       "0  East North Central             710           47097779   \n",
       "2     Middle Atlantic             566           41910858   \n",
       "3            Mountain             311           25514320   \n",
       "4         New England             149           15129548   \n",
       "5             Pacific             490           53229044   \n",
       "6      South Atlantic             222           67452940   \n",
       "\n",
       "   quality_article_number_per_capita  \n",
       "7                           0.000026  \n",
       "1                           0.000019  \n",
       "8                           0.000015  \n",
       "0                           0.000015  \n",
       "2                           0.000014  \n",
       "3                           0.000012  \n",
       "4                           0.000010  \n",
       "5                           0.000009  \n",
       "6                           0.000003  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Census divisions by high quality coverage: Rank ordered list of US census divisions (in descending order) by high quality articles per capita.\n",
    "Divisions_numquality_articles.sort_values(by='quality_article_number_per_capita', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42589cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
